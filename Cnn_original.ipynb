{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "import scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load matlab files\n",
    "\n",
    "Xd=scipy.io.loadmat(r'C:\\Users\\ansel\\Dropbox (MIT)\\Eye_tracking_Last\\Eye_tracker_2_todo\\4_Dataset_Healthy_vs_NeglectHemianopia\\.mat')\n",
    "y=scipy.io.loadmat(r'C:\\Users\\ansel\\Dropbox (MIT)\\Eye_tracking_Last\\Eye_tracker_2_todo\\4_Dataset_Healthy_vs_NeglectHemianopia\\.mat')\n",
    "ypat=scipy.io.loadmat(r'C:\\Users\\ansel\\Dropbox (MIT)\\Eye_tracking_Last\\Eye_tracker_2_todo\\4_Dataset_Healthy_vs_NeglectHemianopia\\.mat')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X=Xd[\"X_all\"]\n",
    "y=y[\"Y_p\"]\n",
    "ypat=np.squeeze(ypat[\"ID_Tr\"])\n",
    "y=np.squeeze(y)\n",
    "\n",
    "dimX=np.shape(X)\n",
    "dimy=np.shape(y)\n",
    "\n",
    "#randomply permute dataset and labels\n",
    "\n",
    "perm = np.random.permutation(dimX[0])\n",
    "\n",
    "X=np.take(X,perm,axis=0,out=X);\n",
    "y=np.take(y,perm,axis=0,out=y);\n",
    "ypat=np.take(ypat,perm,axis=0,out=ypat);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test set\n",
    "\n",
    "#split percentage\n",
    "p=0.8\n",
    "nt=int(np.floor(dimX[0]*p))\n",
    "\n",
    "#train\n",
    "Xtr=X[0:nt,:]\n",
    "ytr=(y[0:nt]+1)/2\n",
    "\n",
    "#test\n",
    "Xts=X[nt+1:-1,:]\n",
    "yts=(y[nt+1:-1]+1)/2\n",
    "\n",
    "ytspat=ypat[nt+1:-1]\n",
    "\n",
    "\n",
    "#get the dimensionality\n",
    "\n",
    "dimXtr=np.shape(Xtr)\n",
    "dimytr=np.shape(ytr)\n",
    "\n",
    "dimXts=np.shape(Xts)\n",
    "dimyts=np.shape(yts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the data to fit in a keras CNN properly\n",
    "# input data needs to be (N, C, X, Y) - shaped where\n",
    "# N - number of samples\n",
    "# C - number of channels per sample\n",
    "# (X, Y) - sample size\n",
    "\n",
    "Xtr = Xtr.reshape((dimXtr[0], 1, dimXtr[1], 1))\n",
    "Xts = Xts.reshape((dimXts[0], 1, dimXts[1], 1))\n",
    "\n",
    "#categorical lebels\n",
    "ytr = np_utils.to_categorical(ytr)\n",
    "yts = np_utils.to_categorical(yts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a CNN\n",
    "\n",
    "cnnbene = Sequential()\n",
    "\n",
    "#2 conv layers\n",
    "cnnbene.add(Conv2D(64, (3, 1),activation=\"relu\",input_shape=(1, dimXtr[1], 1),padding=\"same\"))\n",
    "cnnbene.add(Conv2D(64, (3, 1), activation=\"relu\",padding=\"same\"))\n",
    "\n",
    "#1max pooling layer\n",
    "cnnbene.add(MaxPooling2D(pool_size=(2, 1), data_format=\"channels_first\"))\n",
    "\n",
    "#3conv layers\n",
    "cnnbene.add(Conv2D(128, (3, 1), activation=\"relu\",padding=\"same\"))\n",
    "cnnbene.add(Conv2D(128, (3, 1), activation=\"relu\",padding=\"same\"))\n",
    "cnnbene.add(Conv2D(128, (3, 1), activation=\"relu\",padding=\"same\"))\n",
    "\n",
    "#1max pooling layer\n",
    "cnnbene.add(MaxPooling2D(pool_size=(2, 1), data_format=\"channels_first\"))\n",
    "\n",
    "#3 conv layers\n",
    "cnnbene.add(Conv2D(256, (3, 1), activation=\"relu\",padding=\"same\"))\n",
    "cnnbene.add(Conv2D(256, (3, 1), activation=\"relu\",padding=\"same\"))\n",
    "cnnbene.add(Conv2D(256, (3, 1), activation=\"relu\",padding=\"same\"))\n",
    "\n",
    "#1 max pooling layer\n",
    "cnnbene.add(MaxPooling2D(pool_size=(2, 1), data_format=\"channels_first\"))\n",
    "\n",
    "#2 fully connected layer with dropout regularization \n",
    "cnnbene.add(Flatten())\n",
    "cnnbene.add(Dense(1024, activation=\"relu\"))\n",
    "cnnbene.add(Dropout(0.5))\n",
    "cnnbene.add(Dense(2, activation=\"softmax\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and objective, compile cnn\n",
    "cnnbene.compile(loss=\"categorical_crossentropy\", optimizer='adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=1, nesterov=True)\n",
    "#cnnbene.compile(loss='categorical_crossentropy',\n",
    "#              optimizer=sgd,\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "history=cnnbene.fit(Xtr, ytr, validation_data=(Xts,yts), epochs=15,verbose=2, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "        indx=np.squeeze(np.argwhere(ytspat==i+1))\n",
    "        score = cnnbene.evaluate(Xts[indx,:,:,:], yts[indx])\n",
    "        print('Mean score', i+1,np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    a=len(np.argwhere(ytspat==i+1))\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "\n",
    "#model.save('cnnbene')\n",
    "\n",
    "\n",
    "#cnnbene.save('cnnft.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['accuracy']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
